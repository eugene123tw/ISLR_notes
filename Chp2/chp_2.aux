\relax 
\abx@aux@sortscheme{nyt}
\abx@aux@refcontext{nyt/global/}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {{Chapter}\nobreakspace  {}\nobreakspace  {} 1}Statistical Learning}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}\textbf  {Model}}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}\textbf  {Assessing Model Accuracy}}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}\textbf  {Measuring the Quality of Fit}}{1}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}\textbf  {The Bias-Variance Trade-Off}}{2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The black curve represents the true model $f$. The other curves are $\mathaccentV {hat}05E{f}$ which are used to predict $E(f)$.\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{figure-2.9}{{1}{2}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Anthother $f$ which is closer to linear. The black curve in the left panel is the true $f(X)$. In this setting, linear regression provides a good fit to the data.\relax }}{4}}
\newlabel{figure-2.10}{{2}{4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Anthother $f$ which is far from linear. In this setting, linear regression provides a poor fit to the data.\relax }}{4}}
\newlabel{figure-2.11}{{3}{4}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Square Bias(Blue Curve), Variance(Orange Curve) and MSE(Red Curve) from test data of Figure\nobreakspace  {}1\hbox {}, Figure\nobreakspace  {}2\hbox {} and Figure\nobreakspace  {}3\hbox {}.\relax }}{5}}
\newlabel{figure-2.12}{{4}{5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.3}\textbf  {Classification Settings}}{5}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.4}\textbf  {The Bayes Classifier}}{6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.5}\textbf  {Linear Models and Least Squares}}{6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.6}\textbf  {Nearest-Neighbour Methods: to predict a quantitative response}}{6}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.7}\textbf  {Nearest-Neighbour Methods: to predict a qualitative response}}{7}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}\textbf  {Exercises}}{8}}
